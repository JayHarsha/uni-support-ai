# ğŸ“ University Support AI System

An engineered AI-based ticket classification system designed to reduce pressure on university support offices during peak periods (enrollment week, exam week).

The system automatically:

- Classifies support tickets into predefined categories
- Assigns priority levels
- Logs high-priority events
- Monitors model performance
- Exposes a real-time API endpoint
- Orchestrates the full pipeline using Dagster
- Runs entirely via Docker for reproducibility

---

# ğŸ“Œ Problem Statement

Students submit support requests such as:

- â€œI canâ€™t access my Moodleâ€
- â€œMy fee payment failedâ€
- â€œI need timetable helpâ€
- â€œI have an exam deferral issueâ€
- â€œI forgot my passwordâ€

The system must:

1. Classify each request into one of:
   - IT
   - Fees
   - Timetable
   - Exams
   - General
2. Assign priority:
   - Low
   - Medium
   - High
3. Log events for high-priority tickets
4. Monitor model performance
5. Follow a structured SDLC process
6. Be reproducible and portable

---

# ğŸ— Architecture Overview

The project follows a Layered Architecture with Event Simulation:

Layers:

1. Data Generation Layer (Synthetic Data â†’ PostgreSQL)
2. Training Layer (TF-IDF + Logistic Regression)
3. Inference Layer (Prediction + Event Triggering)
4. Monitoring Layer (Evaluation + Drift Detection)
5. API Layer (FastAPI)
6. Orchestration Layer (Dagster)
7. Infrastructure Layer (Dockerized Services)

Flow:
User â†’ FastAPI â†’ ML Model â†’ PostgreSQL â†’ Event Log â†’ Monitoring â†’ Metrics

---

# ğŸ§  Machine Learning Approach

Feature Extraction:

- TF-IDF (Term Frequencyâ€“Inverse Document Frequency)

Model:

- Logistic Regression (multi-class classification)

Separate models are trained for:

- Category classification
- Priority classification

Evaluation Metrics:

- Accuracy
- Precision (macro)
- Recall (macro)
- F1-score (macro)
- Confusion Matrix
- Average Confidence
- Confidence Drift Over Time

---

# âš™ Technology Stack

ML & Data:

- Python
- NumPy
- Pandas
- Scikit-learn
- Joblib

Backend:

- FastAPI
- Uvicorn

Orchestration:

- Dagster

Database:

- PostgreSQL (Dockerized)

Infrastructure:

- Docker
- Docker Compose

Event Simulation:

- Python Queue
- Database Event Logging

```

# ğŸ“‚ Project Structure

uni-support-ai/
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ db_init.sql
â”œâ”€â”€ dagster_pipeline.py
â”‚
â”œâ”€â”€ api/
â”‚ â””â”€â”€ main.py
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ config.py
â”‚ â”œâ”€â”€ db.py
â”‚ â”œâ”€â”€ data_generation.py
â”‚ â”œâ”€â”€ train_model.py
â”‚ â”œâ”€â”€ inference_service.py
â”‚ â”œâ”€â”€ event_bus.py
â”‚ â””â”€â”€ monitoring.py
â”‚
â”œâ”€â”€ outputs/ (auto-generated)
â”‚ â”œâ”€â”€ category_model.joblib
â”‚ â”œâ”€â”€ priority_model.joblib
â”‚ â”œâ”€â”€ predictions.csv
â”‚ â”œâ”€â”€ events.log
â”‚ â”œâ”€â”€ metrics.json
â”‚ â”œâ”€â”€ confusion_matrix.csv
â”‚ â”œâ”€â”€ high_priority_per_day.csv
â”‚ â””â”€â”€ drift_confidence_over_time.csv
â”‚
â””â”€â”€ README.md

```

# ğŸš€ How To Run (Fully Dockerized)

Prerequisite:

- Install Docker Desktop

Step 1: Clone the repository
git clone <repository_url>
cd uni-support-ai

Step 2: Build and start all services
docker compose up -d --build

This will start:

- PostgreSQL â†’ internal port 5432 (mapped to 5433 locally)
- FastAPI â†’ http://localhost:8000
- Dagster UI â†’ http://localhost:3000

---

# â–¶ Run the Full Pipeline

Open:
http://localhost:3000

1. Go to "Assets"
2. Click "Materialize All"

This will execute:

- Synthetic data generation
- Model training
- Batch inference
- Monitoring & metric computation

---

# ğŸŒ Test the API

Open:
http://localhost:8000/docs

Use:
POST /predict

Example Request:
{
"text": "My fee payment failed and this is urgent"
}

Example Response:
{
"ticket_id": "abc12345",
"category": "Fees",
"priority": "High",
"confidence": 0.82,
"processed_at": "2026-02-16T21:15:00Z"
}

Behavior:

- All predictions are stored in the predictions table.
- If priority = High â†’ event is logged in events table.
- Event is also written to events.log.

---

# ğŸ—„ Database Details

Database Name:
uni_support_ai

Tables:

- tickets
- predictions
- events
- metrics

High-priority predictions trigger event creation.

---

# ğŸ“Š Monitoring Outputs

After pipeline execution, the following files are generated in outputs/:

- metrics.json
- confusion_matrix.csv
- high_priority_per_day.csv
- drift_confidence_over_time.csv

Monitoring computes:

- Category Accuracy
- Macro Precision
- Macro Recall
- Macro F1-score
- Average Confidence
- Per-class performance
- Confidence drift per day

Example baseline performance:

- Category Accuracy â‰ˆ 0.92
- Macro F1 â‰ˆ 0.91
- Balanced performance across 5 categories

---

# ğŸ”„ SDLC Process Followed

1. Planning:
   Defined classification and prioritization goals.

2. Requirements:
   Multi-class classification, priority assignment, monitoring.

3. Design:
   Layered architecture with event-driven simulation.

4. Implementation:
   Modular Python services with clear separation of concerns.

5. Testing:
   - Train-test split
   - API testing via Swagger/Postman
   - Monitoring metrics validation

6. Deployment:
   Fully containerized using Docker Compose.

7. Evolution:
   Drift detection and extensible pipeline via Dagster.

---

# ğŸ³ Why Docker?

Docker ensures:

- Environment consistency
- No local dependency conflicts
- Database isolation
- Reproducibility
- One-command deployment

Anyone can run:
docker compose up -d --build

No local PostgreSQL or Python installation required.

---

# ğŸ” Reset System (If Needed)

To completely reset database and volumes:
docker compose down -v
docker compose up -d --build

---

# ğŸ¯ End-to-End Flow Summary

User Request
â†“
FastAPI Endpoint
â†“
ML Model (TF-IDF + Logistic Regression)
â†“
Prediction Stored in PostgreSQL
â†“
High-Priority Event Logged
â†“
Monitoring Layer Computes Metrics
â†“
Dagster Orchestrates Full Pipeline

---

# âœ… Reproducibility

The system is fully portable and self-contained.

Steps:

1. Install Docker
2. Run docker compose up -d --build
3. Open Dagster UI and materialize
4. Test API via Swagger

No configuration changes required.

---
